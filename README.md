# AI - Reads

Page to register good AI material to read later.

## Transformers

### Core LLMs
- [The Llama 3 Herd of Models](https://scontent.fbom3-2.fna.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=t6egZJ8QdI4Q7kNvgFAjx7y&_nc_ht=scontent.fbom3-2.fna&oh=00_AYBV76QA0hhnN6YXD4cd0_OFrJYN8AW2NBOdQp21U1zVwA&oe=66A5D24D) (92 pages)

### RAG
- [RAG and RAU: A Survey on Retrieval-Augmented LM in NLP](https://arxiv.org/pdf/2404.19543) (arvix pdf)
- [LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](https://tiger-ai-lab.github.io/LongRAG/) (github.io, University of Waterloo)

### Finetuning
- [Llama 3 quantize 8bits with bitsandbytes](https://towardsdatascience.com/quantize-llama-3-8b-with-bitsandbytes-to-preserve-its-accuracy-e84283b233f7)
- [Mistral 7B with DPO](https://mlabonne.github.io/blog/posts/Fine_tune_Mistral_7b_with_DPO.html) (notebook example)
- [Google Research Guidelines for Finetuning](https://github.com/google-research/tuning_playbook)

### Datasets
- [LLMs Datasets](https://github.com/mlabonne/llm-datasets) (github list)
- [The Tome](https://huggingface.co/datasets/arcee-ai/The-Tome) (github)
- [Fine Tome 100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) (github)

### Tools
- [Unsloth Library - Llama3.1+others](https://github.com/unslothai/unsloth): Fine-tuning easily and free.

### Content Moderation
- [ShieldGemma: Generative AI Content Moderation Based on Gemma](https://arxiv.org/abs/2407.21772) (Google LLC, 31-06-2024)

## Computer Vision

### Overall News
- 2024-08-02 [Stable Fast 3D Released](https://stability.ai/news/introducing-stable-fast-3d)

### VLMs
- [OpenVLM Leaderboard](https://huggingface.co/spaces/opencompass/open_vlm_leaderboard) (huggingface board)
- [VLM Architectures](https://github.com/gokayfem/awesome-vlm-architectures/blob/main/README.md) (github)
- [Exploring the Potential of Vision-Language Models (VLMs) A Comprehensive Guide](https://medium.com/thedeephub/exploring-the-potential-of-vision-language-models-vlms-in-ai-a-comprehensive-guide-409b4d897117)
- [An Introduction to VLMs](https://arxiv.org/pdf/2405.17247v1) (arvix pdf)
- [LivePortrait](https://github.com/KwaiVGI/LivePortrait)

### Finetuning
- [Moondream](https://github.com/vikhyat/moondream/blob/main/notebooks/Finetuning.ipynb) (github)

  ## Conferences
  - [ICML'24 - DeepMind Papers](https://deepmind.google/discover/events/icml-2024)
  - [ICML'24 - Best Papers](https://medium.com/@djohraiberra/icml-2024-top-papers-whats-new-in-machine-learning-cca7f9a953e3)

## Graphs
- [Giving a Voice to Your Graph: Representing Structured Data for LLMs](https://media.licdn.com/dms/document/media/D4E1FAQFW0D-CL3pK0w/feedshare-document-pdf-analyzed/0/1721575359199?e=1722470400&v=beta&t=vj3mITRP8IaP14ytitL8nWlNmhvo_--zjjy0dQPJ0i4) (google research, ICML'24)

## Libraries
- [mem0 long contextual memory library for LLMs](https://github.com/mem0ai/mem0)

